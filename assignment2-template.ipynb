{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cdfc308",
   "metadata": {},
   "source": [
    "# COMP4318/COMP5318 Assignment 2\n",
    "\n",
    "In this template, we have provided data loading code and section headings to help structure your notebook. Please refer to the assignment specification pdf to guide the content of your notebook and report.\n",
    "\n",
    "\n",
    "(Add SIDs here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47044b53",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please include your imports in this cell\n",
    "import numpy as np\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD ##needs to be changed to keras\n",
    "import imblearn\n",
    "import sklearn\n",
    "from  sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02a893",
   "metadata": {},
   "source": [
    "# Data loading, exploration, and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea8346",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files assuming Assignment2Data folder \n",
    "# is present in the same directory as the notebook\n",
    "X_train = np.load('Assignment2Data/X_train.npy')\n",
    "y_train = np.load('Assignment2Data/y_train.npy')\n",
    "X_test = np.load('Assignment2Data/X_test.npy')\n",
    "y_test = np.load('Assignment2Data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85476aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, unique_indices = np.unique(y_train, return_index=True)\n",
    "sorted_arr = y_train[unique_indices]\n",
    "print(sorted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "unique_values_1, counts_1 = np.unique(y_train, return_counts=True)\n",
    "unique_values_2, counts_2 = np.unique(y_test, return_counts=True)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(unique_values_1, counts_1)\n",
    "plt.xlabel('Group No.')\n",
    "plt.ylabel('Counts')\n",
    "plt.ylim(bottom = 0, top = 3000)\n",
    "plt.title('Group counts in y_train subset')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(unique_values_2, counts_2)\n",
    "plt.xlabel('Group No.')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Group counts in y_test subset')\n",
    "plt.ylim(bottom = 0, top = 3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd60dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted_arr\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.xlabel(y_train[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86502202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DownScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "X_train_n = X_train /255\n",
    "X_test_n = X_test /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catagorizing\n",
    "num_classes = 8\n",
    "y_train_c = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_c = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dda114",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8934dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_n.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28, 3]),\n",
    "    keras.layers.Dense(128,),\n",
    "    keras.layers.LeakyReLU(alpha=0.05),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(64,),\n",
    "    keras.layers.LeakyReLU(alpha=0.05),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(32,),\n",
    "    keras.layers.LeakyReLU(alpha=0.05),\n",
    "    keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=5e-2)\n",
    "model_mlp.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics= ['categorical_accuracy'])\n",
    "\n",
    "# history = model.fit(X_train_n, y_train_c, epochs=20, batch_size= 16,\n",
    "#                     validation_data=(X_test_n, y_test_c))\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 8\n",
    "epochs = 20\n",
    "history_mlp = model_mlp.fit(X_train_n, y_train_c,batch_size=batch_size,epochs=epochs,validation_data=(X_test_n, y_test_c),shuffle=True,\n",
    "                    )\n",
    "\n",
    "# loss, accuracy = model.evaluate(X_test_n, y_test_c)\n",
    "# print(f\"Accuracy on test data: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "    # Layer 1: Convolutional layer with 64 filters\n",
    "model_4.add(Conv2D(64, (3, 3), padding='same',input_shape=X_train_n.shape[1:]))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "    # Layer 2: Convolutional layer with 64 filters\n",
    "model_4.add(Conv2D(64, (3, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "    # Layer 3: Convolutional layer with 128 filters\n",
    "model_4.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "    # Layer 4: Convolutional layer with 128 filters\n",
    "model_4.add(Conv2D(128, (3, 3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "  # Layer 5: Fully connected layer with 512 units and L2 regularizatio\n",
    "model_4.add(Dense(512,kernel_regularizer=l2(0.01)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "    # Output layer: Fully connected layer with num_classes units for classification\n",
    "model_4.add(Dense(num_classes))\n",
    "model_4.add(Activation('softmax'))\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics= ['categorical_accuracy'])\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 8\n",
    "epochs = 20\n",
    "\n",
    "history_cnn = model_4.fit(X_train_n, y_train_c,batch_size=batch_size,epochs=epochs,validation_data=(X_test_n, y_test_c),shuffle=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r =  np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test_r = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "X_train_r_n =  X_train_r/255.0\n",
    "X_test_r_n = X_test_r/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee188ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "pipe1 = Pipeline([('classifier', SVC(kernel='linear', C = 1))])\n",
    "pipe1.fit(X_train_r_n, y_train)\n",
    "\n",
    "acc = cross_val_score(pipe1, X_train_r_n, y_train, cv = 5)\n",
    "print(\"Training Acc = {:.2f}\".format(acc.mean()))\n",
    "\n",
    "y_pred = pipe1.predict(X_test_r_n)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random forest ensemble method\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train_r_n, y_train)\n",
    "y_pred = model_rf.predict(X_test_r_n)\n",
    "accuracy_score(y_pred,y_test)\n",
    "print(classification_report(y_pred,y_test))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b58d58",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0923c24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bd7d087",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c98dcb",
   "metadata": {},
   "source": [
    "## Examples of preprocessed data\n",
    "Please print/display some examples of your preprocessed data here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639cebf7",
   "metadata": {},
   "source": [
    "# Algorithm design and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5f7a1",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5c15b",
   "metadata": {},
   "source": [
    "## Model 2 - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485c7c2",
   "metadata": {},
   "source": [
    "## Model 3 - Algorithm Choice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533e00f",
   "metadata": {},
   "source": [
    "## Model 4 - Algorithm Choice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91791de6",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326d402",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80654f41",
   "metadata": {},
   "source": [
    "## Model 2 - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a0f71",
   "metadata": {},
   "source": [
    "## Model 3 - Algorithm Choice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd85c65",
   "metadata": {},
   "source": [
    "## Model 4 - Algorithm Choice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82d673",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef0732",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc20752",
   "metadata": {},
   "source": [
    "## Model 2 - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52443c0f",
   "metadata": {},
   "source": [
    "## Model 3 - Algorithm Choice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7462d3ea",
   "metadata": {},
   "source": [
    "## Model 4 - Algorithm Choice 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
