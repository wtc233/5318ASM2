{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cdfc308",
   "metadata": {},
   "source": [
    "# COMP4318/COMP5318 Assignment 2\n",
    "\n",
    "In this template, we have provided data loading code and section headings to help structure your notebook. Please refer to the assignment specification pdf to guide the content of your notebook and report.\n",
    "\n",
    "\n",
    "(Add SIDs here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47044b53",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62cf8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please include your imports in this cell\n",
    "import numpy as np\n",
    "#import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD ##needs to be changed to keras\n",
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from  sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02a893",
   "metadata": {},
   "source": [
    "# Data loading, exploration, and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea8346",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a69fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files assuming Assignment2Data folder \n",
    "# is present in the same directory as the notebook\n",
    "X_train = np.load('Assignment2Data/X_train.npy')\n",
    "y_train = np.load('Assignment2Data/y_train.npy')\n",
    "X_test = np.load('Assignment2Data/X_test.npy')\n",
    "y_test = np.load('Assignment2Data/y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87221de5",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfda882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13673, 28, 28, 3)\n",
      "(3419, 28, 28, 3)\n",
      "(13673,)\n",
      "(3419,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85476aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13cdb4ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Usyd\\COMP 5318\\ASM2\\5318ASM2\\assignment2-template.ipynb 单元格 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Usyd/COMP%205318/ASM2/5318ASM2/assignment2-template.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m unique_values, unique_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_train, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Usyd/COMP%205318/ASM2/5318ASM2/assignment2-template.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sorted_arr \u001b[39m=\u001b[39m y_train[unique_indices]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Usyd/COMP%205318/ASM2/5318ASM2/assignment2-template.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(sorted_arr)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "unique_values, unique_indices = np.unique(y_train, return_index=True)\n",
    "sorted_arr = y_train[unique_indices]\n",
    "print(sorted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "unique_values_1, counts_1 = np.unique(y_train, return_counts=True)\n",
    "unique_values_2, counts_2 = np.unique(y_test, return_counts=True)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(unique_values_1, counts_1)\n",
    "plt.xlabel('Group No.')\n",
    "plt.ylabel('Counts')\n",
    "plt.ylim(bottom = 0, top = 3000)\n",
    "plt.title('Group counts in y_train subset')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(unique_values_2, counts_2)\n",
    "plt.xlabel('Group No.')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Group counts in y_test subset')\n",
    "plt.ylim(bottom = 0, top = 3000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd60dc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Usyd\\COMP 5318\\ASM2\\5318ASM2\\assignment2-template.ipynb 单元格 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Usyd/COMP%205318/ASM2/5318ASM2/assignment2-template.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m class_names \u001b[39m=\u001b[39m sorted_arr\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Usyd/COMP%205318/ASM2/5318ASM2/assignment2-template.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Usyd/COMP%205318/ASM2/5318ASM2/assignment2-template.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m49\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sorted_arr' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = sorted_arr\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.xlabel(y_train[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da4219",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b0e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "X_train_n = X_train /255\n",
    "X_test_n = X_test /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff3239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catagorizing\n",
    "num_classes = 8\n",
    "y_train_c = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_c = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1a807db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r =  np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test_r = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "X_train_r_n =  X_train_r/255.0\n",
    "X_test_r_n = X_test_r/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20dda114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8934dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_n.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60f2fb",
   "metadata": {},
   "source": [
    "## Examples of preprocessed data\n",
    "Please print/display some examples of your preprocessed data here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccbd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted_arr\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.xlabel(y_train[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee188ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "pipe1 = Pipeline([('classifier', SVC(kernel='linear', C = 1))])\n",
    "pipe1.fit(X_train_r_n, y_train)\n",
    "\n",
    "acc = cross_val_score(pipe1, X_train_r_n, y_train, cv = 5)\n",
    "print(\"Training Acc = {:.2f}\".format(acc.mean()))\n",
    "\n",
    "y_pred = pipe1.predict(X_test_r_n)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "371bda03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.439041 using {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.161633 (0.002621) with: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.160389 (0.003493) with: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.125503 (0.003359) with: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.125942 (0.002828) with: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.259929 (0.006343) with: {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.260733 (0.006192) with: {'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.156220 (0.001831) with: {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.153953 (0.001042) with: {'criterion': 'gini', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.364514 (0.004820) with: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.362540 (0.005194) with: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.242668 (0.006386) with: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.238207 (0.004375) with: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.422804 (0.005553) with: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.423609 (0.004300) with: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.344621 (0.010227) with: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.345133 (0.007426) with: {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.160535 (0.001461) with: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.161413 (0.002422) with: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.127332 (0.002813) with: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.127039 (0.002896) with: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.275872 (0.001797) with: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.276311 (0.001773) with: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.157683 (0.001817) with: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.155562 (0.002813) with: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.382140 (0.002456) with: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.382506 (0.001946) with: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.256857 (0.006085) with: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.253639 (0.005026) with: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'n_estimators': 200}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 100}\n",
      "nan (nan) with: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}\n",
      "0.436481 (0.004108) with: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.439041 (0.003767) with: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "0.361954 (0.003601) with: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.362174 (0.004868) with: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# y_pred = model_rf.predict(X_test_r_n)\n",
    "# accuracy_score(y_pred,y_test)\n",
    "# print(classification_report(y_pred,y_test))\n",
    "# cm = confusion_matrix(y_test,y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "# disp.plot()\n",
    "# plt.title('Confusion Matrix for Random Forest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0923c24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639cebf7",
   "metadata": {},
   "source": [
    "# Algorithm design and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5f7a1",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLPmodel(neurons, dropout_rate, activation,):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=[28, 28, 3]))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/4, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(8, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics= ['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5c15b",
   "metadata": {},
   "source": [
    "## Model 2 - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a09de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ConVmodel(activation):\n",
    "    model = Sequential()\n",
    "        # Layer 1: Convolutional layer with 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',input_shape=X_train_n.shape[1:],activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "        # Layer 2: Convolutional layer with 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "        # Layer 3: Convolutional layer with 128 filters\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "        # Layer 4: Convolutional layer with 128 filters\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Layer 5: Fully connected layer with 512 units and L2 regularizatio\n",
    "    model.add(Dense(512,kernel_regularizer=l2(0.01), activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "        # Output layer: Fully connected layer with num_classes units for classification\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics= ['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485c7c2",
   "metadata": {},
   "source": [
    "## Model 3 - Algorithm Choice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533e00f",
   "metadata": {},
   "source": [
    "## Model 4 - Algorithm Choice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91791de6",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326d402",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4da8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLPmodel(neurons, dropout_rate, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=[28, 28, 3]))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/4, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(8, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics= ['categorical_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model_mlp = KerasClassifier(model=create_MLPmodel,verbose=0)\n",
    "\n",
    "neurons = [128, 64, 32]\n",
    "dropout_rate = [0.01,0.1]\n",
    "activation = ['relu']\n",
    "\n",
    "optimizer = ['Adam', 'SGD']\n",
    "batch_size = [32,64]\n",
    "epochs = [20]\n",
    "param_grid = dict(model__neurons=neurons, \n",
    "                    model__dropout_rate=dropout_rate,\n",
    "                    model__activation=activation,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs\n",
    "                  )\n",
    "\n",
    "grid = GridSearchCV(estimator=model_mlp, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_n, y_train_c)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80654f41",
   "metadata": {},
   "source": [
    "## Model 2 - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d851d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ConVmodel(activation):\n",
    "    model = Sequential()\n",
    "        # Layer 1: Convolutional layer with 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',input_shape=X_train_n.shape[1:],activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "        # Layer 2: Convolutional layer with 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "        # Layer 3: Convolutional layer with 128 filters\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "        # Layer 4: Convolutional layer with 128 filters\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Layer 5: Fully connected layer with 512 units and L2 regularizatio\n",
    "    model.add(Dense(512,kernel_regularizer=l2(0.01), activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "        # Output layer: Fully connected layer with num_classes units for classification\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics= ['categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "model_conv = KerasClassifier(model=create_ConVmodel,verbose=0)\n",
    "\n",
    "batch_size = [32, 64]\n",
    "epochs = [3]\n",
    "activation = ['relu', 'tanh']\n",
    "param_grid = dict(batch_size = batch_size,\n",
    "                epochs = epochs,\n",
    "                model__activation=activation\n",
    "                  )\n",
    "\n",
    "num_classes = 8\n",
    "\n",
    "# history_cnn = model_conv.fit(X_train_n, y_train_c,batch_size=batch_size,epochs=epochs,validation_data=(X_test_n, y_test_c),shuffle=True,\n",
    "#                     )\n",
    "grid = GridSearchCV(estimator=model_conv, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_n, y_train_c)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a0f71",
   "metadata": {},
   "source": [
    "## Model 3 - Algorithm Choice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3146a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afd85c65",
   "metadata": {},
   "source": [
    "## Model 4 - Algorithm Choice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random forest ensemble method\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(random_state=2023)\n",
    "\n",
    "\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "param_grid = dict(\n",
    "    max_features = max_features,\n",
    "    criterion = criterion\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(estimator=model_rf, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_r_n, y_train_c)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82d673",
   "metadata": {},
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef0732",
   "metadata": {},
   "source": [
    "## Model 1 - Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MLPmodel(neurons, dropout_rate, activation,):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=[28, 28, 3]))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons/4, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(8, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics= ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model_mlp = create_MLPmodel(256, 0.05, 'relu')\n",
    "history = model_mlp.fit(X_train_n, y_train_c, batch_size = 32, epochs = 50, validation_data =  (X_test_n, y_test_c), shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65540987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelhistory(history): \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "plotmodelhistory(history)\n",
    "\n",
    "y_pred_mlp = model_mlp.predict(X_test_n)\n",
    "Y_Pred_mlp = np.argmax(y_pred_mlp, axis=1)\n",
    "Y_True = np.argmax(y_test_c, axis=1)\n",
    "print(classification_report(Y_True, Y_Pred_mlp))\n",
    "\n",
    "cm = confusion_matrix(Y_Pred_mlp,Y_True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.show()\n",
    "\n",
    "R = 10\n",
    "C = 10\n",
    "fig, axes = plt.subplots(R, C, figsize=(20,20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, R*C):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title(\"True: %s \\nPredict: %s\" % ([Y_True[i]], [Y_Pred_mlp[i]]))\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc20752",
   "metadata": {},
   "source": [
    "## Model 2 - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b80a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ConVmodel(activation):\n",
    "    model = Sequential()\n",
    "        # Layer 1: Convolutional layer with 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',input_shape=X_train_n.shape[1:],activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "        # Layer 2: Convolutional layer with 64 filters\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "        # Layer 3: Convolutional layer with 128 filters\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "        # Layer 4: Convolutional layer with 128 filters\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # Layer 5: Fully connected layer with 512 units and L2 regularizatio\n",
    "    model.add(Dense(512,kernel_regularizer=l2(0.01), activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "        # Output layer: Fully connected layer with num_classes units for classification\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics= ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_conv = create_ConVmodel('relu')\n",
    "history = model_conv.fit(X_train_n, y_train_c, batch_size = 32, epochs = 100, validation_data = (X_test_n, y_test_c), shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelhistory(history): \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(history.history['accuracy']) \n",
    "    axs[0].plot(history.history['val_accuracy']) \n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy') \n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(history.history['loss']) \n",
    "    axs[1].plot(history.history['val_loss']) \n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss') \n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "plotmodelhistory(history)\n",
    "\n",
    "y_pred_conv = model_conv.predict(X_test_n)\n",
    "Y_Pred_conv = np.argmax(y_pred_conv, axis=1)\n",
    "Y_True = np.argmax(y_test_c, axis=1)\n",
    "print(classification_report(Y_True, Y_Pred_conv))\n",
    "cm = confusion_matrix(Y_Pred_conv,Y_True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.show()\n",
    "\n",
    "R = 10\n",
    "C = 10\n",
    "fig, axes = plt.subplots(R, C, figsize=(20,20))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, R*C):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title(\"True: %s \\nPredict: %s\" % ([Y_True[i]], [Y_Pred_conv[i]]))\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52443c0f",
   "metadata": {},
   "source": [
    "## Model 3 - Algorithm Choice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7462d3ea",
   "metadata": {},
   "source": [
    "## Model 4 - Algorithm Choice 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
